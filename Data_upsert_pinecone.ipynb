{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM//N3/Oqvp+edwoP1JV7p3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadanvekar/All-India-Pincode-Directory/blob/master/Data_upsert_pinecone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSXCmfgCa7uK",
        "outputId": "436390b1-e8fa-4151-c766-9af38534d609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Installing collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\n",
            "Successfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install pinecone-client\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PINECONE_API_KEY="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRFjUq4-fw-M",
        "outputId": "9012882d-466b-47f5-c052-6f6a93da9bff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PINECONE_API_KEY=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "#pinecone.init(api_key=\"pcsk_6r6Hde_K6yg7eqVznKda55HScGrZuBv2P17tcm9jaY9Rxf566Ttn5uMxF7Zcxv4kgXA3DM\", environment=\"us-east-1-aws\")  # Replace with your Pinecone API key and environment\n",
        "PINECONE_API_KEY=\"\"\n",
        "\n",
        "pc = Pinecone(\n",
        "    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
        ")\n",
        "\n",
        "index_name=\"shopwise-order-data\"\n",
        "\n",
        "# **Change 1: Set the correct dimension (3072) during index creation**\n",
        "dimension = 3072  # Update this to the actual dimension of your vectors\n",
        "\n",
        "# Create the index if it doesn't exist\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(name= index_name, dimension=dimension\n",
        "                    , metric=\"consine\"\n",
        "                    , spec=ServerlessSpec(\n",
        "                        cloud='aws'\n",
        "                        ,region ='us-east-1'\n",
        "                    )\n",
        "                  )  # Adjust dimension according to your vector size\n",
        "\n",
        "def read_csv(file_path):\n",
        "    ids = []\n",
        "    vectors = []\n",
        "    metadata = []\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # Skip header row\n",
        "        for row in reader:\n",
        "            id = row[0]  # Assuming first column is the ID\n",
        "            #vector = np.array([float(x) for x in row[1:-1] if x.replace('.', '', 1).isdigit()])\n",
        "            #meta = ' '.join([x for x in row[1:-1] if not x.replace('.', '', 1).isdigit()])  # Updated to include potential non-numeric data\n",
        "            # Change 2: Adjust vector extraction to ensure 3072 dimensions\n",
        "            #vector = np.array([float(x) for x in row[1:] if x.replace('.', '', 1).isdigit()])\n",
        "            #meta = ' '.join([x for x in row[1:] if not x.replace('.', '', 1).isdigit()])\n",
        "            #meta = row[-1]  # Last column is metadata\n",
        "            #vector = np.array([float(x) for x in row[1:-1]])  # Assuming the vector is in the columns before the last\n",
        "            #meta = row[-1]  # Last column is metadata\n",
        "\n",
        "            # **Change:** Extract all numeric values after the ID as the vector\n",
        "            vector = np.array([float(x) for x in row[1:] if x.replace('.', '', 1).isdigit()])\n",
        "            # **Change:** If vector has less than 3072 dimensions, pad with zeros\n",
        "            if len(vector) < 3072:\n",
        "                vector = np.pad(vector, (0, 3072 - len(vector)), 'constant')\n",
        "            # **Change:** Extract all non-numeric values after the ID as the metadata\n",
        "            meta = ' '.join([x for x in row[1:] if not x.replace('.', '', 1).isdigit()])\n",
        "\n",
        "            # **Change:** Truncate metadata to a maximum length of 500 characters\n",
        "            meta = meta[:250]  # Truncate metadata\n",
        "\n",
        "\n",
        "            ids.append(id)\n",
        "            vectors.append(vector)\n",
        "            metadata.append(meta)\n",
        "    return ids, vectors, metadata\n",
        "\n",
        "# Optional: Normalize vectors\n",
        "def normalize_vectors(vectors):\n",
        "    return normalize(vectors)\n",
        "\n",
        "# Read and prepare the data\n",
        "ids, vectors, metadata = read_csv(\"synthetic-order-data.csv\")\n",
        "vectors = normalize_vectors(vectors)\n",
        "\n",
        "# Prepare the data for upsert: (id, vector, metadata)\n",
        "data = [(id, vector.tolist(), {'metadata': meta}) for id, vector, meta in zip(ids, vectors, metadata)]\n",
        "\n",
        "# Connect to the Pinecone index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Upsert the data in batches\n",
        "\n",
        "#index.upsert(vectors=data)\n",
        "batch_size = 100  # Set the batch size to 1000\n",
        "for i in range(0, len(data), batch_size):\n",
        "    batch = data[i : i + batch_size]\n",
        "    index.upsert(vectors=batch)\n",
        "    print(f\"Upserted batch {i // batch_size + 1} of {len(data) // batch_size + 1}\")\n",
        "\n",
        "# Verify success\n",
        "print(f\"Successfully upserted {len(data)} vectors into Pinecone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWkWsX49bH5J",
        "outputId": "93400116-ff84-4f6a-cd75-f1a36b620e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserted batch 1 of 25\n",
            "Upserted batch 2 of 25\n",
            "Upserted batch 3 of 25\n",
            "Upserted batch 4 of 25\n",
            "Upserted batch 5 of 25\n",
            "Upserted batch 6 of 25\n",
            "Upserted batch 7 of 25\n",
            "Upserted batch 8 of 25\n",
            "Upserted batch 9 of 25\n",
            "Upserted batch 10 of 25\n",
            "Upserted batch 11 of 25\n",
            "Upserted batch 12 of 25\n",
            "Upserted batch 13 of 25\n",
            "Upserted batch 14 of 25\n",
            "Upserted batch 15 of 25\n",
            "Upserted batch 16 of 25\n",
            "Upserted batch 17 of 25\n",
            "Upserted batch 18 of 25\n",
            "Upserted batch 19 of 25\n",
            "Upserted batch 20 of 25\n",
            "Upserted batch 21 of 25\n",
            "Upserted batch 22 of 25\n",
            "Upserted batch 23 of 25\n",
            "Upserted batch 24 of 25\n",
            "Upserted batch 25 of 25\n",
            "Successfully upserted 2475 vectors into Pinecone.\n"
          ]
        }
      ]
    }
  ]
}